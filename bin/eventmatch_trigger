#!/usr/bin/env python

from argparse import ArgumentParser
import logging.handlers
import os.path
from datetime import datetime
import sys
import configparser
import json
import urllib.parse
import urllib.request
import urllib.error
import psycopg2
# Local imports
from trigger_funcs import create_logger, get_region_name

"""
eventmatch_trigger - An application which adds events to a specified Postgres table, and 
then attemps to match these events with detections that have been recorded in the database.
This application presumes that it will be called by the Product Distribution Product Indexer.
"""

def insert_from_dict(cur, eventdict):
    """
    Take items from event dictionary and insert into event_ext table in database.
    cur: Postgres database cursor object.
    eventdict: Event dictionary with the following fields, all containing STRINGS:
                - type: Message type (usually 'add')
                - id: Event id
                - source: Event source ('us', 'ci', etc.)
                - time: Event time (20110415173724.011)
                - lon: Event longitude
                - lat: Event latitude
                - depth: Event depth
                - mag: Event magnitude
                - loc: Event location (FE Region)
                - uri: Event location on USGS NEIC web site.
    """
    try:
        eventtime = eventdict['time'][:8] + 'T' + eventdict['time'][8:]
        # Add event to database
        cur.execute("insert into event_ext (event_time, event_id, event_lat, event_lon," + \
                    " magnitude) values (%s, %s, %s, %s, %s);", (eventtime, eventdict['id'],
                    eventdict['lat'], eventdict['lon'], eventdict['mag']))
        logger.info("Successfully inserted event '%s' into event_ext table", eventdict['id'])
    except Exception as e:
        logger.error("Failed to insert event '%s' into event_ext table", eventdict['id'], 
                     exc_info=True)

def match_event(conn, cur, eventdict):
    """
    Checks detection_ext table for detection which matches time and location of event. 
    Updates event_match table with event and detection ids once a match is found.
    conn: Postrgres database connection object.
    cur: Postgres database cursor object.
    eid: Unique ID string for event.
    """
    eid = eventdict['id']
    event_lon = float(eventdict['lon'])
    event_lat = float(eventdict['lat'])

    try:
        # Check for detections close in time to event
        query = "select detection_id from detection_ext, event_ext where event_id = '" + \
                eid + "' and detection_time >= event_time and detection_time < " + \
                "(event_time + interval '180' second)"
        long_query = query + " union select 0 where not exists (" + \
                             query + ");"
        cur.execute(long_query)

        # Select first detection that is returned -- might need to modify
        detection_match = cur.fetchone()[0]

        if detection_match != 0:
            info_string = "Detection time match for event '%s' is %s" % (eid, detection_match)
            logger.info(info_string)

            # Get detection coordinates
            query = """select detection_lat, detection_lon from detection_ext where 
                    detection_id = %s""" % str(detection_match)
            cur.execute(query)
            detection_lat, detection_lon = cur.fetchone()
            detection_lat = float(detection_lat)
            detection_lon = float(detection_lon)

            info_string = "Detection match coordinates - %s, %s" % (
                          str(detection_lat), str(detection_lon))
            logger.info(info_string)

            # Check if detection is within 400 sq km of event
            # 400 km equivalent to about 4.0 degrees lat and lon
            if (abs(event_lon - detection_lon) <= 4.0 and abs(event_lat - detection_lat) \
                <= 4.0):
                # Write event ID to corresponding detection in event_match
                # Write time when match was found to event_match table
                info_string = "Event %s and detection %s are a match" % (
                              eid, str(detection_match))
                logger.info(info_string)

                match_time = datetime.utcnow() # Get current UTC time

                # Update event_match table with match

                # Check if detection already has row in event_match table
                query = "select detection_id from event_match where detection_id = " + \
                        str(detection_match)
                long_query = query + " union select 0 where not exists (" + query + ");"
                cur.execute(long_query)
                found_id = cur.fetchone()[0]

                logger.info("Found_id is %s", str(found_id))
              
                # If row exists, update it. Else, create new row for match 
                if found_id != 0:
                    cur.execute("update event_match set event_id = %s, match_time = %s" + \
                                "where detection_id = %s;", (eid, str(match_time), 
                                str(detection_match)))
                    conn.commit()

                    logger.info("Updated row in event_match with event '%s'", eid)
                else:
                    create_time = datetime.utcnow()
                    cur.execute("insert into event_match (detection_id, event_id, match_time, " + \
                                "create_time) values (%s, %s, %s, %s);", 
                                (str(detection_match), eid, str(match_time), str(create_time)))

                    info_string = "Added event_id '%s' and detection_id %s to event_match table" % (
                                  eid, str(detection_match))
                    logger.info(info_string)
    except Exception as e:
        logger.error("Error encountered while matching event %s to detection", eid, 
                     exc_info=True)

def call_matcher(options):
    """
    Called by __main__. Creates event dictionary and calls insert_from_dict(). 
    options: Dictionary with the following fields, all containing STRINGS:
             - status: Event status (default is 'UPDATE')
             - preferredmagnitude: Prefered event magnitude
             - preferredLongitude: Preferred event longitude
             - preferredLatitude: Preferred event latitude
             - code: Event code
             - action: Action to take with event
             - eventIDList: All associated event IDs for event
             - preferredEventTime: Preferred event time
             - source: Network that generated product
             - preferredDepth: Preferred event depth
             - updateTime: Time when this version of event was updated
             - trackerURL: Location where tracking updates are sent 
             - directory: Path to directory that contains product contents
             - preferredID: Preferred event ID
             - type: Event type (should be 'origin')
    """
    # If event is not an event add or event update trigger, exit application
    if options['action'] not in ['EVENT_ADDED','EVENT_UPDATED']:
        info_string = """Unacceptable action '%s'. Ignoring all actions but 'EVENT_ADDED' and
                         'EVENT_UPDATED'. Exiting""" % options['action']
        logger.info(info_string)
        # logger.info("Ignoring all actions but 'EVENT_ADDED' and 'EVENT_UPDATED'. Exiting")
        sys.exit(0)

    # If network source is in ignoreregions list, exit application
    ignoreregions = config.get('SETUP','ignoreregions').split(',')
    if options['source'].lower() in ignoreregions:
        logger.info("Ignoring region '%s'. Exiting", options['source'].lower())
        sys.exit(0)

    # If event code is not same as preferred event ID, exit application
    if options['code'] != options['preferredID']:
        logger.info("Ignoring non-preferred ID '%s'. Exiting", options['code'])
        sys.exit(0)

    try:
        eventdt = datetime.strptime(options['preferredEventTime'],'%Y-%m-%dT%H:%M:%S.%fZ')

        eventdict = {}
        eventdict['type'] = 'add'
        eventdict['id'] = options['preferredID'].lower()
        eventdict['source'] = options['source'].lower()
        eventdict['time'] = eventdt.strftime('%Y%m%d%H%M%S.00')
        eventdict['lat'] = '%.4f' % float(options['preferredLatitude'])
        eventdict['lon'] = '%.4f' % float(options['preferredLongitude'])
        eventdict['depth'] = '%.1f' % float(options['preferredDepth'])
        eventdict['mag'] = '%.1f' % float(options['preferredMagnitude'])
        eventdict['loc'] = get_region_name(float(options['preferredLatitude']),float(options['preferredLongitude']))
        urlt = config.get('SETUP','urltemplate')
        eventdict['uri'] = urlt.replace('[EVENT]',options['preferredID'].lower())
    except Exception as e:
        logger.error("Error caught while creating event dictionary", exc_info=True)

    # Connect to database
    prefix = 'testDB'
    try:
        port = config.get('DATABASE',prefix+'_port')
        user = config.get('DATABASE',prefix+'_user')
        dbname = config.get('DATABASE',prefix+'_name')
        password = config.get('DATABASE',prefix+'_password')
    except Exception as e:
        error_string = "Error getting database arguments from config file. Check that " + \
                       "prefix " + prefix + " matches values in " + str(configfile)
        logger.error(error_string, exc_info=True)

    try:
        conn = psycopg2.connect(dbname=dbname, user=user, port=port, password=password)
        conn.autocommit = True
        cur = conn.cursor()
    except Exception as e:
        logger.error("Error connecting to database", exc_info=True)

    # Add event to database
    insert_from_dict(cur, eventdict)

    # Look for detection that matches event
    match_event(conn, cur, eventdict)

    # Close database connections
    cur.close()
    conn.close()

    # Exit application
    sys.exit(0)

if __name__ == '__main__':
    parser = ArgumentParser(prog='eventmatch_trigger', usage ='%(prog)s [options]')

    # Product Indexer command line API options
    parser.add_argument("--directory", dest="directory",
                      help="""Optional. <directory> is a path to a directory that contains product contents. Any directory
                      hierarchy within <directory> is preserved.""", metavar="DIRECTORY")
    
    parser.add_argument("--type", dest="type",
                      help="""Product TYPE. A short identifier that is shared by all sources of a type of product.
                      Examples include origin, shakemap, pager, etc. """, metavar="TYPE")
    
    parser.add_argument("--code", dest="code",
                      help="""Event CODE: 2 character source code plus 8 character network event code.
                      Examples include us2009abcd and ci12345678""", metavar="CODE")
    
    parser.add_argument("--source", dest="source",
                      help="""Network SOURCE that generated this product, as a two character network code.
                      Examples include us, nc, and ci.""", metavar="SOURCE")
    
    parser.add_argument("--updateTime", dest="updateTime",
                      help="""Optional. Default is now. When this version of source+type+code was updated.
                      An example is 2010-01-14T14:11:28.691-07:00.""", metavar="UPDATETIME")
    
    parser.add_argument("--status", dest="status",
                      help="""Optional. Default is UPDATE. Product generators may use any status without spaces.
                      However, the status must be used consistently for all products of that type.
                      Examples include UPDATE, and DELETE.""", metavar="STATUS")
    
    parser.add_argument("--trackerURL", dest="trackerURL",
                      help="A location where tracking updates are sent.", metavar="TRACKERURL")

    parser.add_argument("--action", dest="action",
                      help="""ACTION is one of: EVENT_ADDED,EVENT_SPLIT,EVENT_UPDATED,EVENT_DELETED,EVENT_MERGED,EVENT_ARCHIVED
                      PRODUCT_ADDED,PRODUCT_UPDATED,PRODUCT_DELETED,PRODUCT_ARCHIVED""", metavar="ACTION")
    
    parser.add_argument("--preferred-eventid", dest="preferredID",
                      help="""The full (source+code) preferred event ID for this event.""", metavar="PREFERREDID")
    
    parser.add_argument("--eventids", dest="eventIDList",
                      help="""All of the associated event IDs for this event.""", metavar="EVENTIDS")
    
    parser.add_argument("--preferred-magnitude", dest="preferredMagnitude",
                      help="""The preferred magnitude for this event.""", metavar="PREFERREDMAG")
    
    parser.add_argument("--preferred-latitude", dest="preferredLatitude",
                      help="""The preferred latitude for this event.""", metavar="PREFERREDLAT")
    
    parser.add_argument("--preferred-longitude", dest="preferredLongitude",
                      help="""The preferred longitude for this event.""", metavar="PREFERREDLON")
    
    parser.add_argument("--preferred-depth", dest="preferredDepth",
                      help="""The preferred depth for this event.""", metavar="PREFERREDDEPTH")
    
    parser.add_argument("--preferred-eventtime", dest="preferredEventTime",
                      help="""The preferred event time (2010-01-14T14:11:28.691Z).""", metavar="PREFERREDDEPTH")
    


    # Filter out any options that are not in the above list
    # Get the list of defined options
    options = {}
    validargs, invalidargs = parser.parse_known_args()
    options = vars(validargs)

    # Print help menu and exit if none of options are defined
    foundone = False
    for argvalue in options.values():
        if argvalue != None:
             foundone = True
             break
    if not foundone:
        parser.print_help()
        sys.exit(0)

    # Check that there is a preferred magnitude (fix to recurring dictionary error)
    if options['preferredMagnitude'] == 'null':
        sys.exit(0)

    # Read in config file
    homedir = os.path.dirname(os.path.abspath(__file__))
    configfile = os.path.join(homedir,'eventmatch_config.ini')
    if not os.path.isfile(configfile):
        print("File \"%s\" does not exist.  Exiting", configfile)
        sys.exit(1)

    config = configparser.ConfigParser()
    config.read_file(open(configfile))

    if not config.has_section('SETUP'):
        print("Config file '%s' is missing section 'SETUP'.  Exiting", configfile)
        sys.exit(1)

    reqoptions = ['ignoreregions','logging_level','logfile']

    missing = []
    for option in reqoptions:
        if not config.has_option('SETUP',option):
            missing.append(option)
    if len(missing):
        print("Config file '%s' is missing SETUP options '%s'.  Exiting", configfile,','.join(missing))
        sys.exit(1)

    # Create dictionary to use when passing parameters into create_logger()
    logdict = {}
    # Instruct logging module when to back up logfile and create new, empty one
    # Logfile will be archived once a week on Sunday, and only 8 will be kept at a time.
    logdict['bkup_inttype'] = 'W6' # W6 = Sunday
    logdict['bkup_interval'] = 1
    logdict['bkup_count'] = 8
    logdict['bkup_suffix'] = '%Y-%m-%d_%H:%M:%S'
    logdict['homedir'] = homedir
    logdict['config'] = config

    # Create logfile
    logger = create_logger(logdict)

    call_matcher(options)    
